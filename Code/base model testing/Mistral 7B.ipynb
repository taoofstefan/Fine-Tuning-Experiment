{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b56e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir --verbose\n",
    "# !pip install huggingface-hub\n",
    "# !pip install --upgrade huggingface_hub\n",
    "# !pip install ipywidgets\n",
    "# !pip install pandas\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import os\n",
    "import time\n",
    "!huggingface-cli login --token hf_\n",
    "!huggingface-cli whoami\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset \n",
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# Specify the new directory you want to change to\n",
    "new_directory = r\"Your-Path\\Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Verify the change\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42267ec-af58-4d89-a4a4-7d19bf13319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama(model_path=\"mistral-7b-instruct-v0.2.Q4_K_M.gguf\",\n",
    "              chat_format=\"mistral-instruct\",\n",
    "              max_tokens=256,\n",
    "              seed=42,\n",
    "              n_gpu_layers=-1,  # Offload all layers to GPU\n",
    "              main_gpu=0  # Specify the main GPU to use\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e304e4d9-c058-4f42-84b3-1356014c9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset('taoofstefan/function_call_weather', split='test')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35a1c4-2c48-4dfe-806d-b57a5d8c3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cea28f-e857-49ea-b55c-322fc911170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be28b85-8747-4a38-a648-3dc51ec69b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant with access to functions. Use the provided function to answer current weather questions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed9bfd-8fbf-4456-9c56-1ed669f833cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer loop for multiple iterations\n",
    "num_iterations = 1  # Number of times the loop should run\n",
    "\n",
    "for j in range(1, num_iterations + 1):  # Start from 1 for correct column numbering\n",
    "    # Record start time for measuring loop duration\n",
    "    start = time.time()\n",
    "\n",
    "    # Loop through the DataFrame's questions\n",
    "    for i in range(0, len(df)):\n",
    "        # Retrieve the current question from the DataFrame\n",
    "        question = df[\"Question\"][i]\n",
    "        \n",
    "        # Define the message structure for the LLM inference\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "        \n",
    "        # Run the LLM inference\n",
    "        result = llm.create_chat_completion(\n",
    "            messages=message,\n",
    "            tools=tools[0]['function'],\n",
    "            tool_choice=\"auto\",    \n",
    "        )\n",
    "        \n",
    "        # Store the assistant's response content, cleaned\n",
    "        assistant_response = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            \n",
    "        # Store in respective columns\n",
    "        df.at[i, f\"Result_{j}\"] = assistant_response\n",
    "\n",
    "        print(result)\n",
    "    \n",
    "    # Record the end time to measure loop duration\n",
    "    end = time.time()\n",
    "\n",
    "    # Calculate the total duration for this `j` iteration\n",
    "    duration = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4937f-8e8f-4f4a-a9b7-354c0f9251d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time LLM worked:\", str(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3851712-5ca6-40cb-a125-06c9b396afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2004d3-60e3-45ad-ad0d-f32594c8b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text if it doesn't start with a '{'\n",
    "def clean_if_not_json(text):\n",
    "    if isinstance(text, str):\n",
    "        if text.startswith(\"{\"):\n",
    "            # No cleaning required\n",
    "            return text\n",
    "        else:\n",
    "            # Strip all commas\n",
    "            return text.replace(\",\", \"\").strip()\n",
    "    return text\n",
    "\n",
    "# List of columns to apply the cleaning function\n",
    "# columns_to_clean = [\"Result_1\", \"Result_2\", \"Result_3\"]\n",
    "columns_to_clean = [\"Result_1\"]\n",
    "\n",
    "# Apply the cleaning function to the specified columns\n",
    "for column in columns_to_clean:\n",
    "    df[column] = df[column].apply(clean_if_not_json)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268085f-a18b-4f81-abf3-375843d95318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV with a specified delimiter\n",
    "df.to_csv(r\"Your-Path\\result_mistral_chat_completion_format.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152666d4-b78b-4e38-bc08-19aec9ba3e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
